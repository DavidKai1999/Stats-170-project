{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b1e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from WMVE import *\n",
    "\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827b378",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3831c10",
   "metadata": {},
   "source": [
    "To make sure this notebook can be run within 1 minute, we use a sample of length 11000 to show how our project work.\n",
    "\n",
    "Since running words embedding would take a long time, we have finished the works for words embedding and data splitting previously, then saved the classifier training, voting testing, and validation sets locally. Here we load these sets from local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc37a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data which has been embedded and split properly for training\n",
    "with open(\".\\\\tempfile\\\\news_data.txt\", \"rb\") as fp:  # Unpickling\n",
    "    X_train, Y_train, X_test, Y_test, X_val, Y_val = pickle.load(fp)\n",
    "\n",
    "X = X_train.copy()\n",
    "X.extend(X_val)\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_train_1 = scaler.transform(X_train)\n",
    "X_test_1 = scaler.transform(X_test)\n",
    "X_val_1 = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b89b6c0",
   "metadata": {},
   "source": [
    "The ratio of the three sets should be approximately 4:1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f68889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5918 1480 1479\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train),len(Y_test),len(Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35401694",
   "metadata": {},
   "source": [
    "All the classifiers had been trained previously, and the model files (including the deep learning model) were saved locally. Here we load the random forest, naive Bayes, and logistic regression models. \n",
    "\n",
    "The BertForSequenceClassification model is a deep learning model. Using it to predict labels is very time-consuming, even on this small sample. Thus, we also saved the prediction results of the BFSC model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacc770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classifiers\n",
    "forest = load(forest_news_model)\n",
    "nb = load(nb_news_model)\n",
    "lr = load(lr_news_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37f2a6",
   "metadata": {},
   "source": [
    "# Evaluate Models on the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5de9430",
   "metadata": {},
   "source": [
    "Here we use the random forest, naive Bayes, logistic regression to predict the validation set and evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7836c0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert accuracy 0.9051299759172687\n",
      "bert f1 0.9108522100832451\n",
      "bert roc_auc 0.9051299759172687\n",
      "bert confusion matrix [[867  69]\n",
      " [ 63 480]]\n",
      "\n",
      "forest accuracy 0.7571667907669397\n",
      "forest f1 0.7560845946242135\n",
      "forest roc_auc 0.7571667907669397\n",
      "forest confusion matrix [[908 435]\n",
      " [ 22 114]]\n",
      "\n",
      "nb accuracy 0.5700728887200551\n",
      "nb f1 0.5132307389241781\n",
      "nb roc_auc 0.5700728887200551\n",
      "nb confusion matrix [[282 103]\n",
      " [648 446]]\n",
      "\n",
      "lr accuracy 0.5418783715677673\n",
      "lr f1 0.5171417582625685\n",
      "lr roc_auc 0.5418783715677674\n",
      "lr confusion matrix [[429 205]\n",
      " [501 344]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\".\\\\tempfile\\\\news_val_pred.txt\", \"rb\") as fp:  # Unpickling\n",
    "    bert_val_pred = pickle.load(fp)\n",
    "forest_val_pred = forest.predict(X_val)\n",
    "nb_val_pred = nb.predict(X_val_1)\n",
    "lr_val_pred = lr.predict(X_val_1)\n",
    "\n",
    "binary_eval('bert',bert_val_pred, Y_val)\n",
    "binary_eval('forest',forest_val_pred, Y_val)\n",
    "binary_eval('nb',nb_val_pred, Y_val)\n",
    "binary_eval('lr',lr_val_pred, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f3f5a",
   "metadata": {},
   "source": [
    "\"comments_voting\" is a self-defined function in WMVE.py. It will extract all Reddit comments (if they exist) for each piece of news, then use the BFSC model to predict labels for all comments. Then, a majority voting (without weight) method will be applied to these predictions to get a voting result as the label of this piece of news. Also, this function will print the performance evaluation of the voting results. \n",
    "\n",
    "Since this step is time-consuming too, we only display the code and the evaluation message in the next chunk. The comment voting result has been saved into a local file so that we can load it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e59325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment_val accuracy 0.6535433070866141\n",
      "comment_val f1 0.7904761904761904\n",
      "comment_val confusion matrix [[83 44]\n",
      " [ 0  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gyiko\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "comment_train_pred = comments_voting(mode='val')\n",
    "\n",
    "with open(\".\\\\tempfile\\\\comment_train_pred.txt\", \"wb\") as fp:  # Pickling\n",
    "    pickle.dump(comment_train_pred, fp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0faba8",
   "metadata": {},
   "source": [
    "The voting weights were calculated with the voting testing set as we introduced in our final report. Here we load and display the voting weights we calculated previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33712eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>BertForSequenceClassification</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Comment Voting</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weights for News Without Comments</td>\n",
       "      <td>0.250916</td>\n",
       "      <td>0.361104</td>\n",
       "      <td>0.203274</td>\n",
       "      <td>0.184706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weights for News With Comments</td>\n",
       "      <td>0.166348</td>\n",
       "      <td>0.273423</td>\n",
       "      <td>0.143403</td>\n",
       "      <td>0.128107</td>\n",
       "      <td>0.288719</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Type  BertForSequenceClassification  \\\n",
       "0  Weights for News Without Comments                       0.250916   \n",
       "1     Weights for News With Comments                       0.166348   \n",
       "\n",
       "   Random Forest  Logistic Regression  Naive Bayes  Comment Voting  Total  \n",
       "0       0.361104             0.203274     0.184706        0.000000    1.0  \n",
       "1       0.273423             0.143403     0.128107        0.288719    1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\".\\\\tempfile\\\\voting_weight.txt\", \"rb\") as fp:  # Unpickling\n",
    "    weight = pickle.load(fp)\n",
    "    \n",
    "weight[0].append(0)\n",
    "\n",
    "bert_weight = [weight[0][0],weight[1][0]]\n",
    "forest_weight = [weight[0][1],weight[1][1]]\n",
    "lr_weight = [weight[0][2],weight[1][2]]\n",
    "nb_weight = [weight[0][3],weight[1][3]]\n",
    "comment_weight = [weight[0][4],weight[1][4]]\n",
    "total = [sum([weight[0][0],weight[0][1],weight[0][2],weight[0][3],weight[0][4]]),\n",
    "        sum([weight[1][0],weight[1][1],weight[1][2],weight[1][3],weight[1][4]])]\n",
    "name = ['Weights for News Without Comments','Weights for News With Comments']\n",
    "\n",
    "pd.DataFrame({'Type':name,\n",
    "              'BertForSequenceClassification':bert_weight,\n",
    "              'Random Forest':forest_weight,\n",
    "             'Logistic Regression':lr_weight,\n",
    "             'Naive Bayes':nb_weight,\n",
    "             'Comment Voting':comment_weight,\n",
    "             'Total':total})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65caf590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f140636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_val accuracy 0.7496562665256478\n",
      "voting_val f1 0.7875736441988426\n",
      "voting_val roc_auc 0.7496562665256478\n",
      "voting_val confusion matrix [[876  54]\n",
      " [243 306]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\".\\\\tempfile\\\\comment_train_pred.txt\", \"rb\") as fp:  # Pickling\n",
    "    comment_train_pred = pickle.load(fp)\n",
    "\n",
    "# Combine all predictions to feed to the weighted voting model\n",
    "classfiers_pred_val = pd.DataFrame({'bert': bert_val_pred,\n",
    "                                      'forest': forest_val_pred,\n",
    "                                      'nb': nb_val_pred,\n",
    "                                      'lr': lr_val_pred,\n",
    "                                      'comment':comment_train_pred})\n",
    "\n",
    "\n",
    "voting_val_pred, prob = WMVEpredict(weight, classfiers_pred_val,use_softmax=False,final=True)\n",
    "\n",
    "binary_eval('voting_val', Y_val, voting_val_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
