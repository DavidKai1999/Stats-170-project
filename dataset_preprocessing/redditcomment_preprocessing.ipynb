{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path\n",
    "redditcomment_path = (\"C:\\\\Users\\\\gyiko\\\\OneDrive - personalmicrosoftsoftware.uci.edu\\\\STATS\\\\STATS 170AB\\\\Project\\\\datasets\\\\fake_news_reddit_cikm20.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do topic modeling for this dataset before running the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data = pd.read_json(redditcomment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>reddit_comments</th>\n",
       "      <th>researched_by</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>snopes</td>\n",
       "      <td>analyze videos growth watch videos growth sinc...</td>\n",
       "      <td>vidinfo</td>\n",
       "      <td>http://www.vidinfo.org/video/67155269/jeremy-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>snopes</td>\n",
       "      <td>last week current administration missed point ...</td>\n",
       "      <td>editorial misinterpreted toon unpatriotic</td>\n",
       "      <td>http://pittnews.com/30440/archives/editorial-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>snopes</td>\n",
       "      <td>email protected member male join date jul 2001...</td>\n",
       "      <td>general health message board</td>\n",
       "      <td>http://www.healthboards.com/boards/general-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>snopes</td>\n",
       "      <td>urban outfitters sunk new low vintage kent sta...</td>\n",
       "      <td>urban outfitters sorry selling kent state swea...</td>\n",
       "      <td>http://gothamist.com/2014/09/15/urban_outfitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>snopes</td>\n",
       "      <td>santa goes many names santa claus st nick kris...</td>\n",
       "      <td>story santa claus</td>\n",
       "      <td>http://www.englishteachermelanie.com/canada-fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label reddit_comments researched_by  \\\n",
       "0      0              []        snopes   \n",
       "1      1              []        snopes   \n",
       "2      0              []        snopes   \n",
       "3      1              []        snopes   \n",
       "4      1              []        snopes   \n",
       "\n",
       "                                                text  \\\n",
       "0  analyze videos growth watch videos growth sinc...   \n",
       "1  last week current administration missed point ...   \n",
       "2  email protected member male join date jul 2001...   \n",
       "3  urban outfitters sunk new low vintage kent sta...   \n",
       "4  santa goes many names santa claus st nick kris...   \n",
       "\n",
       "                                               title  \\\n",
       "0                                            vidinfo   \n",
       "1          editorial misinterpreted toon unpatriotic   \n",
       "2                       general health message board   \n",
       "3  urban outfitters sorry selling kent state swea...   \n",
       "4                                  story santa claus   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.vidinfo.org/video/67155269/jeremy-m...  \n",
       "1  http://pittnews.com/30440/archives/editorial-m...  \n",
       "2  http://www.healthboards.com/boards/general-hea...  \n",
       "3  http://gothamist.com/2014/09/15/urban_outfitte...  \n",
       "4  http://www.englishteachermelanie.com/canada-fu...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to 1NF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 1NF\n",
    "comments = reddit_data['reddit_comments']\n",
    "for i in range(len(comments)):\n",
    "    if comments[i] == []:\n",
    "        comments[i].append('')\n",
    "\n",
    "rclean = reddit_data.fillna(value = '')\n",
    "r1NF = rclean.loc[rclean.index.repeat(comments.str.len())].assign(comments=np.concatenate(comments))\n",
    "r1NF.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r1NF[\"comments\"][701408]\n",
    "\n",
    "comment_author = []\n",
    "comment_text = []\n",
    "comment_score = []\n",
    "comment_subreddit = []\n",
    "comment_label = []\n",
    "\n",
    "for c in r1NF[\"comments\"]:\n",
    "    if c == '':\n",
    "        comment_author.append(None)\n",
    "        comment_text.append(None)\n",
    "        comment_score.append(None)\n",
    "        comment_subreddit.append(None)\n",
    "        comment_label.append(None)\n",
    "    else:\n",
    "        comment_author.append(c['author'])\n",
    "        comment_text.append(c['body'])\n",
    "        comment_score.append(c['score'])\n",
    "        comment_subreddit.append(c['subreddit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1NF_new = r1NF.assign(comment_author = comment_author,\n",
    "                      comment_text = comment_text,\n",
    "                      comment_score = comment_score,\n",
    "                      comment_subreddit = comment_subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1NF_new = r1NF_new.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1NF_new = r1NF_new.drop(columns=['reddit_comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"exportpath = \"C:\\\\Users\\\\gyiko\\\\OneDrive - personalmicrosoftsoftware.uci.edu\\\\STATS\\\\STATS 170AB\\\\Project\\\\datasets\\\\\"\n",
    "\n",
    "# Export Reddit Comment Data\n",
    "json_name = \"RedditData_1NF.json\"\n",
    "r1NF_new.to_json(exportpath + json_name)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode json dictionary to store in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import codecs\n",
    "\n",
    "comments = r1NF_new['comments']\n",
    "\n",
    "r1NF_new['comments'] = [codecs.encode(pickle.dumps(c),'base64').decode() for c in comments] # Encode comments\n",
    "\n",
    "r1NF_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1NF_new = r1NF_new.drop_duplicates(subset=['title','comment_author'],keep=\"last\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'postgres'\n",
    "password = 'postgres'\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://'+user+':'+password+'@localhost/news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = r1NF_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(\"redditcomment\", con=engine, if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = \"SELECT * FROM redditcomment\"\n",
    "df = pd.read_sql_query(Query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>researched_by</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>comments</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>snopes</td>\n",
       "      <td>comprehensive database us voter fraud uncovers...</td>\n",
       "      <td>news21 2012 national project</td>\n",
       "      <td>http://votingrights.news21.com/article/electio...</td>\n",
       "      <td>gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSk9mKVBYBQAAAG...</td>\n",
       "      <td>indy_ttt</td>\n",
       "      <td>analysis resulting comprehensive news21 electi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>snopes</td>\n",
       "      <td>comprehensive database us voter fraud uncovers...</td>\n",
       "      <td>news21 2012 national project</td>\n",
       "      <td>http://votingrights.news21.com/article/electio...</td>\n",
       "      <td>gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSoxoKVBYBQAAAG...</td>\n",
       "      <td>onique</td>\n",
       "      <td>population 330 million people clearly isnt pro...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>snopes</td>\n",
       "      <td>comprehensive database us voter fraud uncovers...</td>\n",
       "      <td>news21 2012 national project</td>\n",
       "      <td>http://votingrights.news21.com/article/electio...</td>\n",
       "      <td>gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSrBnKVBYBQAAAG...</td>\n",
       "      <td>JayBowls</td>\n",
       "      <td>theyre desperate</td>\n",
       "      <td>2.0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>snopes</td>\n",
       "      <td>comprehensive database us voter fraud uncovers...</td>\n",
       "      <td>news21 2012 national project</td>\n",
       "      <td>http://votingrights.news21.com/article/electio...</td>\n",
       "      <td>gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSuNoKVBYBQAAAG...</td>\n",
       "      <td>indy_ttt</td>\n",
       "      <td>problem want dems vote</td>\n",
       "      <td>1.0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>snopes</td>\n",
       "      <td>megan thompson asked national association chai...</td>\n",
       "      <td>generic drugs necessarily mean low prices</td>\n",
       "      <td>http://www.pbs.org/newshour/bb/health-july-dec...</td>\n",
       "      <td>gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSk6zdVJYBQAAAG...</td>\n",
       "      <td>beatyatoit</td>\n",
       "      <td>discovered recently trying get script generic ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label researched_by                                               text  \\\n",
       "0      0        snopes  comprehensive database us voter fraud uncovers...   \n",
       "1      0        snopes  comprehensive database us voter fraud uncovers...   \n",
       "2      0        snopes  comprehensive database us voter fraud uncovers...   \n",
       "3      0        snopes  comprehensive database us voter fraud uncovers...   \n",
       "4      1        snopes  megan thompson asked national association chai...   \n",
       "\n",
       "                                       title  \\\n",
       "0               news21 2012 national project   \n",
       "1               news21 2012 national project   \n",
       "2               news21 2012 national project   \n",
       "3               news21 2012 national project   \n",
       "4  generic drugs necessarily mean low prices   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://votingrights.news21.com/article/electio...   \n",
       "1  http://votingrights.news21.com/article/electio...   \n",
       "2  http://votingrights.news21.com/article/electio...   \n",
       "3  http://votingrights.news21.com/article/electio...   \n",
       "4  http://www.pbs.org/newshour/bb/health-july-dec...   \n",
       "\n",
       "                                            comments comment_author  \\\n",
       "0  gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSk9mKVBYBQAAAG...       indy_ttt   \n",
       "1  gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSoxoKVBYBQAAAG...         onique   \n",
       "2  gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSrBnKVBYBQAAAG...       JayBowls   \n",
       "3  gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSuNoKVBYBQAAAG...       indy_ttt   \n",
       "4  gAN9cQAoWAsAAABjcmVhdGVkX3V0Y3EBSk6zdVJYBQAAAG...     beatyatoit   \n",
       "\n",
       "                                        comment_text  comment_score  \\\n",
       "0  analysis resulting comprehensive news21 electi...            2.0   \n",
       "1  population 330 million people clearly isnt pro...            1.0   \n",
       "2                                   theyre desperate            2.0   \n",
       "3                             problem want dems vote            1.0   \n",
       "4  discovered recently trying get script generic ...            3.0   \n",
       "\n",
       "  comment_subreddit  \n",
       "0          politics  \n",
       "1          politics  \n",
       "2          politics  \n",
       "3          politics  \n",
       "4            Health  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_utc': 1344890447,\n",
       " 'label': 0,\n",
       " 'author': 'indy_ttt',\n",
       " 'comment_id': 'c5sls54',\n",
       " 'subreddit': 'politics',\n",
       " 'score': 2,\n",
       " 'body': 'analysis resulting comprehensive news21 election fraud database turned 10 cases voter impersonation 146 million registered voters united states time 10 cases represent one every 15 million prospective voters disgusting red state republicans conjuring fraud keep minorities voting',\n",
       " 'depth': 0,\n",
       " 'post_id': 'y5w4d',\n",
       " 'parent_id': 't3_y5w4d'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode json dictionary\n",
    "\n",
    "import pickle\n",
    "import codecs\n",
    "\n",
    "test = df.comments[0]\n",
    "pickle.loads(codecs.decode(test.encode(),'base64'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
